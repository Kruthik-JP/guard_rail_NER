# ğŸš§ Guard Rail NER Project  

![GitHub](https://img.shields.io/github/license/Kruthik-JP/guard_rail_NER)  
![Python](https://img.shields.io/badge/Python-3.10-blue)  
![PyTorch](https://img.shields.io/badge/PyTorch-2.1-red)  

A **Secure AI Chatbot and NER system** for guard rail data and sensitive document handling.  
This project ensures **all new uploaded data, including PDFs and sensitive info (PAN, Aadhaar, etc.), is automatically protected** using NER and PII handling, making it safe against instruction-breaking inputs.  

---

## ğŸ” Project Overview  
The **Guard Rail NER system** is designed to:  
- Provide a **secure chatbot** with advanced Guardrails applied at multiple stages:  
  - Data Extraction  
  - Pre-Embedding  
  - Pre-API  
  - Pre-LLM  
- Automatically protect sensitive information using **NER and PII handling**.  
- Detect and classify entities from guard railâ€“related documents and structured/unstructured text.  
- Ensure safety against **malicious or instruction-breaking inputs** during processing.  

---

## ğŸ›  Features  
- âœ… Secure chatbot framework with **multi-layer Guardrails**.  
- âœ… Automatic detection & masking of **sensitive information** (PAN, Aadhaar, etc.).  
- âœ… Advanced **NER pipeline** for entity extraction & classification.  
- âœ… Preprocessing, segmentation, and **safe embeddings** for LLM inputs.  
- âœ… Cloud-ready deployment for **multi-user secure access**.  
- âœ… Easily extendable to **new datasets and documents**.  

---



---

## ğŸ’» Installation & Setup  

1. **Clone the repository**  
```bash
git clone https://github.com/Kruthik-JP/guard_rail_NER.git
cd guard_rail_NER

##2. ** Create a virtual environment**

python -m venv venv
venv\Scripts\activate    # For Windows
# or
source venv/bin/activate # For Linux/Mac

3. Install dependencies

pip install -r requirements.txt

4. Run the project

python main.py


âš™ï¸ Scripts

preprocess.py â€“ Preprocess uploaded documents and safe embedding.

train.py â€“ Train models for entity extraction and classification.

predict.py â€“ Predict entities and protect sensitive data.

evaluate.py â€“ Evaluate model accuracy and data protection metrics.


ğŸ“Š Model & Guardrail Details

NER Models â€“ Entity extraction and PII detection.

Pre-Embedding Guardrails â€“ Filters and masks sensitive data before embedding.

Pre-API Guardrails â€“ Validates requests & prevents unsafe API calls.

Pre-LLM Guardrails â€“ Ensures instruction-following safety.

Secure Pipeline â€“ Data flow:

Upload â†’ Processing â†’ Embedding â†’ LLM Input (Protected)




ğŸ“ Contribution Guidelines
Fork the repository.

Create a new branch for your feature/fix:

bash
Copy
Edit
git checkout -b feature-name
Commit your changes:

bash
Copy
Edit
git commit -m "Add feature/fix description"
Push and create a Pull Request.

ğŸ“§ Author
Kruthik JP

GitHub: Kruthik-JP

Email:kruthikjp.ai@gmail.com


ğŸ“Œ References

Guardrails AI â€“ Framework for adding safety layers to LLM applications.

Microsoft Presidio â€“ Open-source tool for detecting and anonymizing PII.

spaCy â€“ Industrial-strength NLP library for NER.

Hugging Face Transformers â€“ Pretrained models for token classification & NER.

FAISS â€“ Vector similarity search library for fast embedding retrieval.

Chroma DB â€“ Open-source embedding database for document storage & retrieval.

LangChain + Google Generative AI â€“ For embeddings and secure chatbot integration.

FastAPI â€“ Modern Python framework for building APIs and chatbot backends.

Docker â€“ Containerization and deployment.


## ğŸ“ File Structure  

GUARD_RAIL_NER/
â”‚
â”œâ”€â”€ app/                                # Core application code
â”‚   â”œâ”€â”€ __pycache__/                     # Python cache files
â”‚   â”œâ”€â”€ resumes/                         # Uploaded resumes/documents
â”‚   â”œâ”€â”€ static/                          # Static assets for frontend
â”‚   â”‚   â””â”€â”€ style.css                    # CSS styling for chatbot UI
â”‚   â”œâ”€â”€ templates/                       # Frontend templates (Jinja2/FastAPI)
â”‚   â”‚   â””â”€â”€ index.html                   # Main HTML page for chatbot interface
â”‚   â”œâ”€â”€ __init__.py                      # Marks app/ as a package
â”‚   â”œâ”€â”€ chroma_client.py                 # ChromaDB client (vector database)
â”‚   â”œâ”€â”€ embedder.py                      # Embedding functions for documents
â”‚   â”œâ”€â”€ faiss_index.index                # FAISS vector DB index (local storage)
â”‚   â”œâ”€â”€ gemini_client.py                 # Google Gemini API client
â”‚   â”œâ”€â”€ guardrails.py                    # Guardrails (security & PII filtering)
â”‚   â”œâ”€â”€ main.py                          # Main FastAPI application entry
â”‚   â”œâ”€â”€ pdf_utils.py                     # PDF parsing & text extraction utils
â”‚   â””â”€â”€ resume_texts.pkl                 # Pre-processed & serialized resume data
â”‚
â”œâ”€â”€ data/                                # Data handling layer
â”‚   â””â”€â”€ resumes/                         # Resume dataset (raw files)
â”‚       â””â”€â”€ read_resume.py               # Script to parse/process resumes
â”‚
â”œâ”€â”€ resumes/                             # (Optional) Folder for uploads
â”‚
â”œâ”€â”€ venv/                                # Python virtual environment
â”‚
â”œâ”€â”€ .env                                 # Environment variables (API keys, DB config)
â”œâ”€â”€ Dockerfile                           # Containerization config for deployment
â”œâ”€â”€ faiss_index.index                    # Root-level FAISS index (global DB)
â”œâ”€â”€ rebuild                              # (Possibly a build/output directory)
â”œâ”€â”€ requirements.txt                     # Python dependencies
â””â”€â”€ resume_texts.pkl                     # Root-level pickle file (resume data)

âœ… Observations:

You have two copies of:

faiss_index.index (one in app/, one in root)

resume_texts.pkl (one in app/, one in root)
ğŸ‘‰ Better to keep only one (maybe in data/) for cleaner structure.

main.py is the entry point â†’ runs FastAPI backend.

templates/index.html + static/style.css â†’ gives you a basic UI for chatbot/resume upload.

guardrails.py + pdf_utils.py + pii detection (if added later) â†’ are your security & data processing layers.

chroma_client.py + faiss_index.index + embedder.py â†’ form your vector database + embedding pipeline.
